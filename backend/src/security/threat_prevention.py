"""
Threat Prevention Service
========================

Advanced threat prevention and cybersecurity service for financial applications.
Provides real-time threat detection, prevention, and response capabilities.
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union, Set
from dataclasses import dataclass
from enum import Enum
import json
import hashlib
import uuid
import re
from collections import defaultdict, deque

from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, func


class ThreatType(Enum):
    """Types of security threats."""
    MALWARE = "malware"
    PHISHING = "phishing"
    SQL_INJECTION = "sql_injection"
    XSS = "xss"
    CSRF = "csrf"
    BRUTE_FORCE = "brute_force"
    DDoS = "ddos"
    DATA_EXFILTRATION = "data_exfiltration"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    INSIDER_THREAT = "insider_threat"
    API_ABUSE = "api_abuse"
    CREDENTIAL_STUFFING = "credential_stuffing"


class ThreatSeverity(Enum):
    """Threat severity levels."""
    INFO = "info"
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class ResponseAction(Enum):
    """Threat response actions."""
    LOG = "log"
    ALERT = "alert"
    BLOCK = "block"
    QUARANTINE = "quarantine"
    ESCALATE = "escalate"
    INVESTIGATE = "investigate"


@dataclass
class ThreatIndicator:
    """Individual threat indicator."""
    indicator_id: str
    indicator_type: str
    threat_type: ThreatType
    severity: ThreatSeverity
    confidence: float
    description: str
    evidence: Dict[str, Any]
    source: str
    timestamp: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'indicator_id': self.indicator_id,
            'indicator_type': self.indicator_type,
            'threat_type': self.threat_type.value,
            'severity': self.severity.value,
            'confidence': self.confidence,
            'description': self.description,
            'evidence': self.evidence,
            'source': self.source,
            'timestamp': self.timestamp.isoformat()
        }


@dataclass
class ThreatAssessment:
    """Comprehensive threat assessment result."""
    assessment_id: str
    target_id: str
    target_type: str
    overall_threat_score: float
    threat_level: ThreatSeverity
    recommended_actions: List[ResponseAction]
    threat_indicators: List[ThreatIndicator]
    attack_vectors: List[str]
    mitigation_recommendations: List[str]
    assessment_timestamp: datetime
    expires_at: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'assessment_id': self.assessment_id,
            'target_id': self.target_id,
            'target_type': self.target_type,
            'overall_threat_score': self.overall_threat_score,
            'threat_level': self.threat_level.value,
            'recommended_actions': [action.value for action in self.recommended_actions],
            'threat_indicators': [indicator.to_dict() for indicator in self.threat_indicators],
            'attack_vectors': self.attack_vectors,
            'mitigation_recommendations': self.mitigation_recommendations,
            'assessment_timestamp': self.assessment_timestamp.isoformat(),
            'expires_at': self.expires_at.isoformat()
        }


class ThreatPreventionService:
    """
    Advanced threat prevention service for financial applications.
    
    Features:
    - Real-time threat detection and analysis
    - Web application firewall (WAF) capabilities
    - API security and rate limiting
    - Malware detection and prevention
    - Phishing and social engineering detection
    - DDoS protection and mitigation
    - Intrusion detection and prevention
    - Behavioral threat analysis
    - Threat intelligence integration
    - Automated incident response
    """
    
    def __init__(self, db_session: Session, config: Dict[str, Any] = None):
        self.db = db_session
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # Threat prevention components
        self._threat_signatures = {}
        self._behavioral_baselines = {}
        self._threat_intelligence = {}
        self._rate_limiters = {}
        self._blocked_entities = {}
        self._security_rules = {}
        
        # Detection thresholds
        self._threat_thresholds = {
            ThreatSeverity.INFO: 0.1,
            ThreatSeverity.LOW: 0.3,
            ThreatSeverity.MEDIUM: 0.5,
            ThreatSeverity.HIGH: 0.7,
            ThreatSeverity.CRITICAL: 0.9
        }
        
        # Initialize threat prevention service
        self._initialize_threat_prevention()
    
    def _initialize_threat_prevention(self):
        """Initialize the threat prevention service."""
        
        # Load threat signatures
        self._load_threat_signatures()
        
        # Initialize security rules
        self._initialize_security_rules()
        
        # Load threat intelligence
        self._load_threat_intelligence()
        
        # Initialize rate limiters
        self._initialize_rate_limiters()
        
        # Set up behavioral baselines
        self._initialize_behavioral_baselines()
        
        self.logger.info("Threat prevention service initialized successfully")
    
    def _load_threat_signatures(self):
        """Load threat detection signatures."""
        
        # SQL Injection signatures
        self._threat_signatures[ThreatType.SQL_INJECTION] = [
            r"(\b(SELECT|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER|EXEC|UNION)\b)",
            r"(\b(OR|AND)\s+\d+\s*=\s*\d+)",
            r"(\b(OR|AND)\s+['\"]?\w+['\"]?\s*=\s*['\"]?\w+['\"]?)",
            r"(--|#|/\*|\*/)",
            r"(\bUNION\s+(ALL\s+)?SELECT\b)",
            r"(\b(EXEC|EXECUTE)\s+\w+)",
            r"(\b(CAST|CONVERT|CHAR|ASCII)\s*\()",
            r"(\b(WAITFOR|DELAY)\s+['\"]?\d+['\"]?)"
        ]
        
        # XSS signatures
        self._threat_signatures[ThreatType.XSS] = [
            r"(<script[^>]*>.*?</script>)",
            r"(javascript\s*:)",
            r"(on\w+\s*=\s*['\"][^'\"]*['\"])",
            r"(<iframe[^>]*>)",
            r"(<object[^>]*>)",
            r"(<embed[^>]*>)",
            r"(<link[^>]*>)",
            r"(<meta[^>]*>)",
            r"(eval\s*\()",
            r"(document\.(write|writeln|cookie))",
            r"(window\.(location|open))"
        ]
        
        # Command injection signatures
        self._threat_signatures[ThreatType.MALWARE] = [
            r"(\b(cmd|powershell|bash|sh)\s+)",
            r"(\b(wget|curl|nc|netcat)\s+)",
            r"(\b(chmod|chown|sudo)\s+)",
            r"(\|\s*(cat|ls|ps|id|whoami|uname))",
            r"(\$\(.*\))",
            r"(`.*`)",
            r"(\b(rm|del|format)\s+)"
        ]
        
        # Phishing signatures
        self._threat_signatures[ThreatType.PHISHING] = [
            r"(urgent.{0,20}action.{0,20}required)",
            r"(verify.{0,20}account.{0,20}immediately)",
            r"(suspended.{0,20}account)",
            r"(click.{0,20}here.{0,20}now)",
            r"(limited.{0,20}time.{0,20}offer)",
            r"(congratulations.{0,20}winner)",
            r"(security.{0,20}alert)",
            r"(update.{0,20}payment.{0,20}information)"
        ]
    
    def _initialize_security_rules(self):
        """Initialize security rules and policies."""
        
        self._security_rules = {
            'rate_limiting': {
                'api_requests_per_minute': 100,
                'login_attempts_per_hour': 5,
                'password_reset_per_day': 3,
                'transaction_requests_per_hour': 50
            },
            'input_validation': {
                'max_input_length': 10000,
                'allowed_file_types': ['.jpg', '.jpeg', '.png', '.pdf', '.doc', '.docx'],
                'max_file_size_mb': 10,
                'blocked_extensions': ['.exe', '.bat', '.cmd', '.scr', '.vbs', '.js']
            },
            'authentication': {
                'max_failed_attempts': 5,
                'lockout_duration_minutes': 30,
                'password_min_length': 8,
                'require_mfa': True,
                'session_timeout_minutes': 30
            },
            'network_security': {
                'blocked_countries': ['XX', 'YY'],  # High-risk countries
                'blocked_ip_ranges': ['192.168.100.0/24'],
                'require_https': True,
                'block_tor_exit_nodes': True
            }
        }
    
    def _load_threat_intelligence(self):
        """Load threat intelligence data."""
        
        # Mock threat intelligence feeds
        self._threat_intelligence = {
            'malicious_ips': {
                '192.168.1.100': {
                    'threat_type': 'botnet',
                    'confidence': 0.9,
                    'last_seen': datetime.utcnow() - timedelta(hours=2),
                    'source': 'ThreatFeed Pro'
                },
                '10.0.0.50': {
                    'threat_type': 'malware_c2',
                    'confidence': 0.85,
                    'last_seen': datetime.utcnow() - timedelta(hours=6),
                    'source': 'CyberIntel'
                }
            },
            'malicious_domains': {
                'malicious-site.com': {
                    'threat_type': 'phishing',
                    'confidence': 0.95,
                    'last_seen': datetime.utcnow() - timedelta(hours=1),
                    'source': 'PhishTank'
                },
                'fake-bank.net': {
                    'threat_type': 'financial_fraud',
                    'confidence': 0.9,
                    'last_seen': datetime.utcnow() - timedelta(hours=4),
                    'source': 'FinCERT'
                }
            },
            'malicious_hashes': {
                'a1b2c3d4e5f6': {
                    'threat_type': 'banking_trojan',
                    'confidence': 0.98,
                    'last_seen': datetime.utcnow() - timedelta(hours=3),
                    'source': 'MalwareDB'
                }
            }
        }
    
    def _initialize_rate_limiters(self):
        """Initialize rate limiting mechanisms."""
        
        self._rate_limiters = {
            'api_requests': defaultdict(lambda: deque()),
            'login_attempts': defaultdict(lambda: deque()),
            'password_resets': defaultdict(lambda: deque()),
            'transaction_requests': defaultdict(lambda: deque())
        }
    
    def _initialize_behavioral_baselines(self):
        """Initialize behavioral analysis baselines."""
        
        self._behavioral_baselines = {
            'normal_request_patterns': {
                'avg_requests_per_minute': 10,
                'typical_request_sizes': [100, 500, 1000],  # bytes
                'common_user_agents': [
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
                    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
                    'Mozilla/5.0 (X11; Linux x86_64)'
                ],
                'typical_response_times': [50, 100, 200]  # milliseconds
            },
            'normal_login_patterns': {
                'typical_login_hours': list(range(6, 23)),  # 6 AM to 11 PM
                'common_locations': ['US', 'CA', 'GB', 'DE'],
                'session_duration_minutes': [15, 30, 60, 120]
            }
        }
    
    async def assess_request_threat(self, request_data: Dict[str, Any]) -> ThreatAssessment:
        """
        Assess threat level for an incoming request.
        
        Args:
            request_data: Request information for threat assessment
            
        Returns:
            ThreatAssessment containing threat analysis results
        """
        
        assessment_id = str(uuid.uuid4())
        request_id = request_data.get('request_id', 'unknown')
        
        try:
            self.logger.info(f"Starting threat assessment for request {request_id}")
            
            threat_indicators = []
            
            # Input validation and injection detection
            injection_indicators = await self._detect_injection_attacks(request_data)
            threat_indicators.extend(injection_indicators)
            
            # Rate limiting checks
            rate_limit_indicators = await self._check_rate_limits(request_data)
            threat_indicators.extend(rate_limit_indicators)
            
            # IP reputation checks
            ip_reputation_indicators = await self._check_ip_reputation(request_data)
            threat_indicators.extend(ip_reputation_indicators)
            
            # Behavioral analysis
            behavioral_indicators = await self._analyze_request_behavior(request_data)
            threat_indicators.extend(behavioral_indicators)
            
            # File upload security
            if 'file_uploads' in request_data:
                file_indicators = await self._analyze_file_uploads(request_data['file_uploads'])
                threat_indicators.extend(file_indicators)
            
            # Calculate overall threat score
            overall_threat_score = self._calculate_threat_score(threat_indicators)
            
            # Determine threat level
            threat_level = self._determine_threat_level(overall_threat_score)
            
            # Determine recommended actions
            recommended_actions = self._determine_response_actions(threat_level, threat_indicators)
            
            # Identify attack vectors
            attack_vectors = self._identify_attack_vectors(threat_indicators)
            
            # Generate mitigation recommendations
            mitigation_recommendations = self._generate_mitigation_recommendations(threat_indicators)
            
            assessment = ThreatAssessment(
                assessment_id=assessment_id,
                target_id=request_id,
                target_type="request",
                overall_threat_score=overall_threat_score,
                threat_level=threat_level,
                recommended_actions=recommended_actions,
                threat_indicators=threat_indicators,
                attack_vectors=attack_vectors,
                mitigation_recommendations=mitigation_recommendations,
                assessment_timestamp=datetime.utcnow(),
                expires_at=datetime.utcnow() + timedelta(minutes=15)
            )
            
            # Execute immediate response actions
            await self._execute_response_actions(assessment, request_data)
            
            self.logger.info(f"Threat assessment completed for request {request_id}: {threat_level.value}")
            return assessment
            
        except Exception as e:
            self.logger.error(f"Error in threat assessment for request {request_id}: {str(e)}")
            
            return ThreatAssessment(
                assessment_id=assessment_id,
                target_id=request_id,
                target_type="request",
                overall_threat_score=0.5,
                threat_level=ThreatSeverity.MEDIUM,
                recommended_actions=[ResponseAction.LOG, ResponseAction.INVESTIGATE],
                threat_indicators=[ThreatIndicator(
                    indicator_id=f"error_{int(datetime.utcnow().timestamp())}",
                    indicator_type="assessment_error",
                    threat_type=ThreatType.API_ABUSE,
                    severity=ThreatSeverity.MEDIUM,
                    confidence=0.1,
                    description=f"Error in threat assessment: {str(e)}",
                    evidence={'error': str(e)},
                    source="threat_prevention",
                    timestamp=datetime.utcnow()
                )],
                attack_vectors=[],
                mitigation_recommendations=['Investigate assessment error'],
                assessment_timestamp=datetime.utcnow(),
                expires_at=datetime.utcnow() + timedelta(minutes=15)
            )
    
    async def _detect_injection_attacks(self, request_data: Dict[str, Any]) -> List[ThreatIndicator]:
        """Detect injection attacks in request data."""
        
        indicators = []
        
        # Check all input fields
        inputs_to_check = []
        
        # URL parameters
        if 'url_params' in request_data:
            inputs_to_check.extend(request_data['url_params'].values())
        
        # POST data
        if 'post_data' in request_data:
            inputs_to_check.extend(request_data['post_data'].values())
        
        # Headers
        if 'headers' in request_data:
            inputs_to_check.extend(request_data['headers'].values())
        
        # Check each input against threat signatures
        for input_value in inputs_to_check:
            if not isinstance(input_value, str):
                continue
            
            # SQL Injection detection
            sql_matches = self._check_signatures(input_value, ThreatType.SQL_INJECTION)
            if sql_matches:
                indicators.append(ThreatIndicator(
                    indicator_id=f"sqli_{int(datetime.utcnow().timestamp())}",
                    indicator_type="sql_injection",
                    threat_type=ThreatType.SQL_INJECTION,
                    severity=ThreatSeverity.HIGH,
                    confidence=0.9,
                    description="SQL injection attempt detected",
                    evidence={'input': input_value[:100], 'matches': sql_matches},
                    source="signature_detection",
                    timestamp=datetime.utcnow()
                ))
            
            # XSS detection
            xss_matches = self._check_signatures(input_value, ThreatType.XSS)
            if xss_matches:
                indicators.append(ThreatIndicator(
                    indicator_id=f"xss_{int(datetime.utcnow().timestamp())}",
                    indicator_type="cross_site_scripting",
                    threat_type=ThreatType.XSS,
                    severity=ThreatSeverity.HIGH,
                    confidence=0.85,
                    description="Cross-site scripting attempt detected",
                    evidence={'input': input_value[:100], 'matches': xss_matches},
                    source="signature_detection",
                    timestamp=datetime.utcnow()
                ))
            
            # Command injection detection
            cmd_matches = self._check_signatures(input_value, ThreatType.MALWARE)
            if cmd_matches:
                indicators.append(ThreatIndicator(
                    indicator_id=f"cmdi_{int(datetime.utcnow().timestamp())}",
                    indicator_type="command_injection",
                    threat_type=ThreatType.MALWARE,
                    severity=ThreatSeverity.CRITICAL,
                    confidence=0.95,
                    description="Command injection attempt detected",
                    evidence={'input': input_value[:100], 'matches': cmd_matches},
                    source="signature_detection",
                    timestamp=datetime.utcnow()
                ))
        
        return indicators
    
    def _check_signatures(self, input_value: str, threat_type: ThreatType) -> List[str]:
        """Check input against threat signatures."""
        
        matches = []
        signatures = self._threat_signatures.get(threat_type, [])
        
        for signature in signatures:
            if re.search(signature, input_value, re.IGNORECASE):
                matches.append(signature)
        
        return matches
    
    async def _check_rate_limits(self, request_data: Dict[str, Any]) -> List[ThreatIndicator]:
        """Check for rate limiting violations."""
        
        indicators = []
        client_ip = request_data.get('client_ip', '')
        user_id = request_data.get('user_id', '')
        request_type = request_data.get('request_type', 'api')
        
        # Determine rate limit key
        rate_limit_key = user_id if user_id else client_ip
        
        if not rate_limit_key:
            return indicators
        
        current_time = datetime.utcnow()
        
        # Check API request rate limit
        if request_type == 'api':
            api_requests = self._rate_limiters['api_requests'][rate_limit_key]
            api_requests.append(current_time)
            
            # Remove old requests (older than 1 minute)
            cutoff = current_time - timedelta(minutes=1)
            while api_requests and api_requests[0] < cutoff:
                api_requests.popleft()
            
            # Check if rate limit exceeded
            max_requests = self._security_rules['rate_limiting']['api_requests_per_minute']
            if len(api_requests) > max_requests:
                indicators.append(ThreatIndicator(
                    indicator_id=f"rate_limit_{int(datetime.utcnow().timestamp())}",
                    indicator_type="rate_limit_exceeded",
                    threat_type=ThreatType.API_ABUSE,
                    severity=ThreatSeverity.MEDIUM,
                    confidence=0.9,
                    description=f"API rate limit exceeded: {len(api_requests)} requests in 1 minute",
                    evidence={
                        'request_count': len(api_requests),
                        'limit': max_requests,
                        'client_ip': client_ip,
                        'user_id': user_id
                    },
                    source="rate_limiter",
                    timestamp=datetime.utcnow()
                ))
        
        # Check login attempt rate limit
        elif request_type == 'login':
            login_attempts = self._rate_limiters['login_attempts'][rate_limit_key]
            login_attempts.append(current_time)
            
            # Remove old attempts (older than 1 hour)
            cutoff = current_time - timedelta(hours=1)
            while login_attempts and login_attempts[0] < cutoff:
                login_attempts.popleft()
            
            # Check if rate limit exceeded
            max_attempts = self._security_rules['rate_limiting']['login_attempts_per_hour']
            if len(login_attempts) > max_attempts:
                indicators.append(ThreatIndicator(
                    indicator_id=f"login_rate_limit_{int(datetime.utcnow().timestamp())}",
                    indicator_type="login_rate_limit_exceeded",
                    threat_type=ThreatType.BRUTE_FORCE,
                    severity=ThreatSeverity.HIGH,
                    confidence=0.95,
                    description=f"Login rate limit exceeded: {len(login_attempts)} attempts in 1 hour",
                    evidence={
                        'attempt_count': len(login_attempts),
                        'limit': max_attempts,
                        'client_ip': client_ip,
                        'user_id': user_id
                    },
                    source="rate_limiter",
                    timestamp=datetime.utcnow()
                ))
        
        return indicators
    
    async def _check_ip_reputation(self, request_data: Dict[str, Any]) -> List[ThreatIndicator]:
        """Check IP reputation against threat intelligence."""
        
        indicators = []
        client_ip = request_data.get('client_ip', '')
        
        if not client_ip:
            return indicators
        
        # Check against malicious IP database
        if client_ip in self._threat_intelligence['malicious_ips']:
            threat_info = self._threat_intelligence['malicious_ips'][client_ip]
            
            indicators.append(ThreatIndicator(
                indicator_id=f"malicious_ip_{int(datetime.utcnow().timestamp())}",
                indicator_type="malicious_ip",
                threat_type=ThreatType.MALWARE,
                severity=ThreatSeverity.HIGH,
                confidence=threat_info['confidence'],
                description=f"Request from known malicious IP: {threat_info['threat_type']}",
                evidence={
                    'ip_address': client_ip,
                    'threat_type': threat_info['threat_type'],
                    'source': threat_info['source'],
                    'last_seen': threat_info['last_seen'].isoformat()
                },
                source="threat_intelligence",
                timestamp=datetime.utcnow()
            ))
        
        # Check against blocked countries
        country_code = request_data.get('country_code', '')
        blocked_countries = self._security_rules['network_security']['blocked_countries']
        
        if country_code in blocked_countries:
            indicators.append(ThreatIndicator(
                indicator_id=f"blocked_country_{int(datetime.utcnow().timestamp())}",
                indicator_type="blocked_geography",
                threat_type=ThreatType.API_ABUSE,
                severity=ThreatSeverity.MEDIUM,
                confidence=0.8,
                description=f"Request from blocked country: {country_code}",
                evidence={
                    'country_code': country_code,
                    'ip_address': client_ip
                },
                source="geo_blocking",
                timestamp=datetime.utcnow()
            ))
        
        # Check for Tor exit nodes
        if self._is_tor_exit_node(client_ip):
            indicators.append(ThreatIndicator(
                indicator_id=f"tor_exit_{int(datetime.utcnow().timestamp())}",
                indicator_type="tor_exit_node",
                threat_type=ThreatType.API_ABUSE,
                severity=ThreatSeverity.MEDIUM,
                confidence=0.9,
                description="Request from Tor exit node",
                evidence={'ip_address': client_ip},
                source="tor_detection",
                timestamp=datetime.utcnow()
            ))
        
        return indicators
    
    async def _analyze_request_behavior(self, request_data: Dict[str, Any]) -> List[ThreatIndicator]:
        """Analyze request behavioral patterns."""
        
        indicators = []
        
        # Check request size
        request_size = request_data.get('request_size', 0)
        max_size = self._security_rules['input_validation']['max_input_length']
        
        if request_size > max_size:
            indicators.append(ThreatIndicator(
                indicator_id=f"large_request_{int(datetime.utcnow().timestamp())}",
                indicator_type="oversized_request",
                threat_type=ThreatType.DDoS,
                severity=ThreatSeverity.MEDIUM,
                confidence=0.7,
                description=f"Oversized request: {request_size} bytes",
                evidence={'request_size': request_size, 'max_size': max_size},
                source="behavioral_analysis",
                timestamp=datetime.utcnow()
            ))
        
        # Check user agent
        user_agent = request_data.get('user_agent', '')
        if self._is_suspicious_user_agent(user_agent):
            indicators.append(ThreatIndicator(
                indicator_id=f"suspicious_ua_{int(datetime.utcnow().timestamp())}",
                indicator_type="suspicious_user_agent",
                threat_type=ThreatType.API_ABUSE,
                severity=ThreatSeverity.LOW,
                confidence=0.6,
                description="Suspicious user agent detected",
                evidence={'user_agent': user_agent},
                source="behavioral_analysis",
                timestamp=datetime.utcnow()
            ))
        
        # Check for unusual request patterns
        request_path = request_data.get('request_path', '')
        if self._is_suspicious_path(request_path):
            indicators.append(ThreatIndicator(
                indicator_id=f"suspicious_path_{int(datetime.utcnow().timestamp())}",
                indicator_type="suspicious_request_path",
                threat_type=ThreatType.API_ABUSE,
                severity=ThreatSeverity.MEDIUM,
                confidence=0.8,
                description="Suspicious request path detected",
                evidence={'request_path': request_path},
                source="behavioral_analysis",
                timestamp=datetime.utcnow()
            ))
        
        return indicators
    
    async def _analyze_file_uploads(self, file_uploads: List[Dict[str, Any]]) -> List[ThreatIndicator]:
        """Analyze uploaded files for security threats."""
        
        indicators = []
        
        for file_info in file_uploads:
            filename = file_info.get('filename', '')
            file_size = file_info.get('file_size', 0)
            file_content = file_info.get('content', b'')
            
            # Check file extension
            file_ext = '.' + filename.split('.')[-1].lower() if '.' in filename else ''
            blocked_extensions = self._security_rules['input_validation']['blocked_extensions']
            
            if file_ext in blocked_extensions:
                indicators.append(ThreatIndicator(
                    indicator_id=f"blocked_file_{int(datetime.utcnow().timestamp())}",
                    indicator_type="blocked_file_type",
                    threat_type=ThreatType.MALWARE,
                    severity=ThreatSeverity.HIGH,
                    confidence=0.9,
                    description=f"Blocked file type uploaded: {file_ext}",
                    evidence={'filename': filename, 'extension': file_ext},
                    source="file_analysis",
                    timestamp=datetime.utcnow()
                ))
            
            # Check file size
            max_size_mb = self._security_rules['input_validation']['max_file_size_mb']
            max_size_bytes = max_size_mb * 1024 * 1024
            
            if file_size > max_size_bytes:
                indicators.append(ThreatIndicator(
                    indicator_id=f"oversized_file_{int(datetime.utcnow().timestamp())}",
                    indicator_type="oversized_file",
                    threat_type=ThreatType.DDoS,
                    severity=ThreatSeverity.MEDIUM,
                    confidence=0.8,
                    description=f"Oversized file upload: {file_size} bytes",
                    evidence={'filename': filename, 'file_size': file_size, 'max_size': max_size_bytes},
                    source="file_analysis",
                    timestamp=datetime.utcnow()
                ))
            
            # Basic malware detection
            if self._contains_malware_signatures(file_content):
                indicators.append(ThreatIndicator(
                    indicator_id=f"malware_file_{int(datetime.utcnow().timestamp())}",
                    indicator_type="malware_detected",
                    threat_type=ThreatType.MALWARE,
                    severity=ThreatSeverity.CRITICAL,
                    confidence=0.95,
                    description="Potential malware detected in uploaded file",
                    evidence={'filename': filename, 'file_size': file_size},
                    source="malware_scanner",
                    timestamp=datetime.utcnow()
                ))
        
        return indicators
    
    def _calculate_threat_score(self, threat_indicators: List[ThreatIndicator]) -> float:
        """Calculate overall threat score from indicators."""
        
        if not threat_indicators:
            return 0.0
        
        # Weighted average based on severity and confidence
        total_weighted_score = 0.0
        total_weight = 0.0
        
        severity_weights = {
            ThreatSeverity.INFO: 0.1,
            ThreatSeverity.LOW: 0.3,
            ThreatSeverity.MEDIUM: 0.5,
            ThreatSeverity.HIGH: 0.8,
            ThreatSeverity.CRITICAL: 1.0
        }
        
        for indicator in threat_indicators:
            severity_weight = severity_weights[indicator.severity]
            weight = severity_weight * indicator.confidence
            total_weighted_score += weight
            total_weight += weight
        
        if total_weight == 0:
            return 0.0
        
        base_score = total_weighted_score / total_weight
        
        # Apply indicator count multiplier
        indicator_multiplier = min(1.0 + (len(threat_indicators) - 1) * 0.1, 1.5)
        
        return min(base_score * indicator_multiplier, 1.0)
    
    def _determine_threat_level(self, threat_score: float) -> ThreatSeverity:
        """Determine threat level based on threat score."""
        
        if threat_score >= self._threat_thresholds[ThreatSeverity.CRITICAL]:
            return ThreatSeverity.CRITICAL
        elif threat_score >= self._threat_thresholds[ThreatSeverity.HIGH]:
            return ThreatSeverity.HIGH
        elif threat_score >= self._threat_thresholds[ThreatSeverity.MEDIUM]:
            return ThreatSeverity.MEDIUM
        elif threat_score >= self._threat_thresholds[ThreatSeverity.LOW]:
            return ThreatSeverity.LOW
        else:
            return ThreatSeverity.INFO
    
    def _determine_response_actions(self, threat_level: ThreatSeverity,
                                  threat_indicators: List[ThreatIndicator]) -> List[ResponseAction]:
        """Determine appropriate response actions."""
        
        actions = []
        
        # Always log
        actions.append(ResponseAction.LOG)
        
        # Determine actions based on threat level
        if threat_level == ThreatSeverity.CRITICAL:
            actions.extend([ResponseAction.BLOCK, ResponseAction.ALERT, ResponseAction.ESCALATE])
        elif threat_level == ThreatSeverity.HIGH:
            actions.extend([ResponseAction.BLOCK, ResponseAction.ALERT])
        elif threat_level == ThreatSeverity.MEDIUM:
            actions.extend([ResponseAction.ALERT, ResponseAction.INVESTIGATE])
        elif threat_level == ThreatSeverity.LOW:
            actions.append(ResponseAction.ALERT)
        
        # Check for specific threat types requiring immediate blocking
        critical_threats = {ThreatType.SQL_INJECTION, ThreatType.MALWARE, ThreatType.XSS}
        has_critical_threat = any(indicator.threat_type in critical_threats for indicator in threat_indicators)
        
        if has_critical_threat and ResponseAction.BLOCK not in actions:
            actions.append(ResponseAction.BLOCK)
        
        return actions
    
    def _identify_attack_vectors(self, threat_indicators: List[ThreatIndicator]) -> List[str]:
        """Identify attack vectors from threat indicators."""
        
        attack_vectors = set()
        
        for indicator in threat_indicators:
            if indicator.threat_type == ThreatType.SQL_INJECTION:
                attack_vectors.add("SQL Injection")
            elif indicator.threat_type == ThreatType.XSS:
                attack_vectors.add("Cross-Site Scripting")
            elif indicator.threat_type == ThreatType.MALWARE:
                attack_vectors.add("Malware/Command Injection")
            elif indicator.threat_type == ThreatType.BRUTE_FORCE:
                attack_vectors.add("Brute Force Attack")
            elif indicator.threat_type == ThreatType.DDoS:
                attack_vectors.add("Denial of Service")
            elif indicator.threat_type == ThreatType.API_ABUSE:
                attack_vectors.add("API Abuse")
            elif indicator.threat_type == ThreatType.PHISHING:
                attack_vectors.add("Phishing")
        
        return list(attack_vectors)
    
    def _generate_mitigation_recommendations(self, threat_indicators: List[ThreatIndicator]) -> List[str]:
        """Generate mitigation recommendations."""
        
        recommendations = set()
        
        for indicator in threat_indicators:
            if indicator.threat_type == ThreatType.SQL_INJECTION:
                recommendations.add("Implement parameterized queries and input validation")
                recommendations.add("Use web application firewall (WAF) rules")
            elif indicator.threat_type == ThreatType.XSS:
                recommendations.add("Implement output encoding and content security policy")
                recommendations.add("Validate and sanitize all user inputs")
            elif indicator.threat_type == ThreatType.MALWARE:
                recommendations.add("Implement file upload restrictions and scanning")
                recommendations.add("Use application sandboxing")
            elif indicator.threat_type == ThreatType.BRUTE_FORCE:
                recommendations.add("Implement account lockout policies")
                recommendations.add("Use CAPTCHA and multi-factor authentication")
            elif indicator.threat_type == ThreatType.DDoS:
                recommendations.add("Implement rate limiting and traffic shaping")
                recommendations.add("Use DDoS protection services")
            elif indicator.threat_type == ThreatType.API_ABUSE:
                recommendations.add("Implement API rate limiting and authentication")
                recommendations.add("Monitor API usage patterns")
        
        return list(recommendations)
    
    async def _execute_response_actions(self, assessment: ThreatAssessment, request_data: Dict[str, Any]):
        """Execute immediate response actions."""
        
        client_ip = request_data.get('client_ip', '')
        user_id = request_data.get('user_id', '')
        
        for action in assessment.recommended_actions:
            if action == ResponseAction.BLOCK:
                await self._block_entity(client_ip, user_id, assessment)
            elif action == ResponseAction.ALERT:
                await self._send_security_alert(assessment)
            elif action == ResponseAction.ESCALATE:
                await self._escalate_incident(assessment)
            elif action == ResponseAction.QUARANTINE:
                await self._quarantine_entity(client_ip, user_id, assessment)
    
    async def _block_entity(self, client_ip: str, user_id: str, assessment: ThreatAssessment):
        """Block IP address or user account."""
        
        block_duration = timedelta(hours=24)  # Default 24 hour block
        
        if client_ip:
            self._blocked_entities[client_ip] = {
                'blocked_at': datetime.utcnow(),
                'expires_at': datetime.utcnow() + block_duration,
                'reason': f"Threat assessment: {assessment.threat_level.value}",
                'assessment_id': assessment.assessment_id
            }
            self.logger.warning(f"Blocked IP address: {client_ip}")
        
        if user_id:
            self._blocked_entities[user_id] = {
                'blocked_at': datetime.utcnow(),
                'expires_at': datetime.utcnow() + block_duration,
                'reason': f"Threat assessment: {assessment.threat_level.value}",
                'assessment_id': assessment.assessment_id
            }
            self.logger.warning(f"Blocked user account: {user_id}")
    
    async def _send_security_alert(self, assessment: ThreatAssessment):
        """Send security alert to monitoring systems."""
        
        alert_data = {
            'alert_type': 'security_threat',
            'severity': assessment.threat_level.value,
            'target': assessment.target_id,
            'threat_score': assessment.overall_threat_score,
            'indicators': len(assessment.threat_indicators),
            'timestamp': assessment.assessment_timestamp.isoformat()
        }
        
        # In practice, this would send alerts to SIEM, email, Slack, etc.
        self.logger.warning(f"Security alert: {json.dumps(alert_data)}")
    
    async def _escalate_incident(self, assessment: ThreatAssessment):
        """Escalate security incident to security team."""
        
        incident_data = {
            'incident_type': 'security_threat',
            'severity': assessment.threat_level.value,
            'assessment_id': assessment.assessment_id,
            'target': assessment.target_id,
            'attack_vectors': assessment.attack_vectors,
            'timestamp': assessment.assessment_timestamp.isoformat()
        }
        
        # In practice, this would create tickets in incident management systems
        self.logger.critical(f"Security incident escalated: {json.dumps(incident_data)}")
    
    async def _quarantine_entity(self, client_ip: str, user_id: str, assessment: ThreatAssessment):
        """Quarantine entity for further investigation."""
        
        # Similar to blocking but with different handling
        await self._block_entity(client_ip, user_id, assessment)
        self.logger.warning(f"Quarantined entity - IP: {client_ip}, User: {user_id}")
    
    def _is_suspicious_user_agent(self, user_agent: str) -> bool:
        """Check if user agent is suspicious."""
        
        suspicious_patterns = [
            'bot', 'crawler', 'spider', 'scraper', 'automated',
            'curl', 'wget', 'python', 'java', 'go-http'
        ]
        
        user_agent_lower = user_agent.lower()
        return any(pattern in user_agent_lower for pattern in suspicious_patterns)
    
    def _is_suspicious_path(self, request_path: str) -> bool:
        """Check if request path is suspicious."""
        
        suspicious_patterns = [
            '/admin', '/wp-admin', '/phpmyadmin', '/config',
            '/.env', '/.git', '/backup', '/test',
            '../', '..\\', '/etc/passwd', '/proc/',
            'eval(', 'base64_decode', 'system('
        ]
        
        path_lower = request_path.lower()
        return any(pattern in path_lower for pattern in suspicious_patterns)
    
    def _is_tor_exit_node(self, ip_address: str) -> bool:
        """Check if IP is a Tor exit node."""
        
        # Mock implementation - would check against Tor exit node lists
        return 'tor' in ip_address.lower()
    
    def _contains_malware_signatures(self, file_content: bytes) -> bool:
        """Check file content for malware signatures."""
        
        # Mock implementation - would use actual malware scanning
        malware_signatures = [
            b'EICAR-STANDARD-ANTIVIRUS-TEST-FILE',
            b'X5O!P%@AP[4\\PZX54(P^)7CC)7}$EICAR',
            b'eval(base64_decode(',
            b'system(',
            b'exec(',
            b'shell_exec('
        ]
        
        for signature in malware_signatures:
            if signature in file_content:
                return True
        
        return False
    
    def is_entity_blocked(self, entity_id: str) -> bool:
        """Check if an entity (IP or user) is currently blocked."""
        
        if entity_id not in self._blocked_entities:
            return False
        
        block_info = self._blocked_entities[entity_id]
        
        # Check if block has expired
        if datetime.utcnow() > block_info['expires_at']:
            del self._blocked_entities[entity_id]
            return False
        
        return True
    
    def unblock_entity(self, entity_id: str) -> bool:
        """Manually unblock an entity."""
        
        if entity_id in self._blocked_entities:
            del self._blocked_entities[entity_id]
            self.logger.info(f"Manually unblocked entity: {entity_id}")
            return True
        
        return False
    
    def get_threat_statistics(self) -> Dict[str, Any]:
        """Get threat prevention service statistics."""
        
        return {
            'threat_signatures': sum(len(sigs) for sigs in self._threat_signatures.values()),
            'blocked_entities': len(self._blocked_entities),
            'threat_intelligence_ips': len(self._threat_intelligence['malicious_ips']),
            'threat_intelligence_domains': len(self._threat_intelligence['malicious_domains']),
            'security_rules': len(self._security_rules),
            'rate_limiters': len(self._rate_limiters),
            'last_updated': datetime.utcnow().isoformat()
        }

